{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "import logging\n",
    " \n",
    "import tensorflow\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, GlobalAveragePooling1D, Embedding\n",
    "from tensorflow.keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model, Sequential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoplist = [i.strip() for i in open('停用词.txt', encoding = 'utf-8').readlines()]\n",
    "def m_cut(intxt):\n",
    "    word = [w for w in jieba.cut(intxt) if w not in stoplist and len(w) > 1 and not re.match('^[a-z|A-Z|0-9|.]*$',w)]\n",
    "    strword = \" \".join(word)\n",
    "    return strword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>评论文本</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>西安进过一个月半终于低风险了[允悲]#西安今天起恢复正常出行#</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>上高速看核酸不</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[哈哈]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>终于等来了全面恢复正常出行的好消息[心][good]，大家终于可以赶上过个快乐年了！</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>什么时候可以出市</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>莫名其妙 低风险地区过来为啥还要48小时核酸，脱了裤子放屁。有绿码还不够吗</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>有人知道坐高铁在西安转站有啥要求不？</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>不知道上下防疫政策不不同步的难度在哪里？</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[吃瓜]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[赞][赞][赞]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         评论文本  class\n",
       "0             西安进过一个月半终于低风险了[允悲]#西安今天起恢复正常出行#      1\n",
       "1                                     上高速看核酸不      1\n",
       "2                                        [哈哈]      1\n",
       "3  终于等来了全面恢复正常出行的好消息[心][good]，大家终于可以赶上过个快乐年了！      1\n",
       "4                                    什么时候可以出市      1\n",
       "5       莫名其妙 低风险地区过来为啥还要48小时核酸，脱了裤子放屁。有绿码还不够吗      1\n",
       "6                          有人知道坐高铁在西安转站有啥要求不？      1\n",
       "7                        不知道上下防疫政策不不同步的难度在哪里？      1\n",
       "8                                        [吃瓜]      1\n",
       "9                                   [赞][赞][赞]      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = pd.read_excel('review_data.xlsx', sheet_name = 0)\n",
    "raw_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\u1128714\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 2.460 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0       西安 一个月 终于 风险 允悲 西安 恢复正常 出行\n",
       "1                            高速 核酸\n",
       "2                                 \n",
       "3       终于 恢复正常 出行 好消息 终于 赶上 过个 快乐\n",
       "4                               出市\n",
       "5    莫名其妙 风险 地区 为啥 小时 核酸 裤子 放屁 有绿码\n",
       "6                      有人 高铁 西安 转站\n",
       "7                      防疫 政策 同步 难度\n",
       "8                               吃瓜\n",
       "9                                 \n",
       "Name: 评论文本, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#预处理\n",
    "data = raw_data.copy()\n",
    "\n",
    "#去除空值\n",
    "data['评论文本'] = data['评论文本'].dropna(how='any')\n",
    "data['评论文本'] = data['评论文本'].astype(str)\n",
    "\n",
    "#去停词，分词\n",
    "data['评论文本'] = data['评论文本'].apply(m_cut)\n",
    "data['评论文本'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines=data['评论文本'].values.tolist()\n",
    "content = \"\".join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-02 11:42:16,361 : INFO : collecting all words and their counts\n",
      "2022-04-02 11:42:16,362 : WARNING : Each 'sentences' item should be a list of words (usually unicode strings). First item here is instead plain <class 'str'>.\n",
      "2022-04-02 11:42:16,363 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-04-02 11:42:16,381 : INFO : PROGRESS: at sentence #10000, processed 10000 words, keeping 1006 word types\n",
      "2022-04-02 11:42:16,414 : INFO : PROGRESS: at sentence #20000, processed 20000 words, keeping 1364 word types\n",
      "2022-04-02 11:42:16,439 : INFO : PROGRESS: at sentence #30000, processed 30000 words, keeping 1679 word types\n",
      "2022-04-02 11:42:16,478 : INFO : PROGRESS: at sentence #40000, processed 40000 words, keeping 1836 word types\n",
      "2022-04-02 11:42:16,498 : INFO : PROGRESS: at sentence #50000, processed 50000 words, keeping 1937 word types\n",
      "2022-04-02 11:42:16,529 : INFO : PROGRESS: at sentence #60000, processed 60000 words, keeping 2045 word types\n",
      "2022-04-02 11:42:16,545 : INFO : PROGRESS: at sentence #70000, processed 70000 words, keeping 2166 word types\n",
      "2022-04-02 11:42:16,581 : INFO : PROGRESS: at sentence #80000, processed 80000 words, keeping 2234 word types\n",
      "2022-04-02 11:42:16,598 : INFO : PROGRESS: at sentence #90000, processed 90000 words, keeping 2314 word types\n",
      "2022-04-02 11:42:16,614 : INFO : PROGRESS: at sentence #100000, processed 100000 words, keeping 2408 word types\n",
      "2022-04-02 11:42:16,643 : INFO : PROGRESS: at sentence #110000, processed 110000 words, keeping 2476 word types\n",
      "2022-04-02 11:42:16,660 : INFO : PROGRESS: at sentence #120000, processed 120000 words, keeping 2544 word types\n",
      "2022-04-02 11:42:16,697 : INFO : PROGRESS: at sentence #130000, processed 130000 words, keeping 2591 word types\n",
      "2022-04-02 11:42:16,712 : INFO : PROGRESS: at sentence #140000, processed 140000 words, keeping 2627 word types\n",
      "2022-04-02 11:42:16,754 : INFO : PROGRESS: at sentence #150000, processed 150000 words, keeping 2665 word types\n",
      "2022-04-02 11:42:16,774 : INFO : PROGRESS: at sentence #160000, processed 160000 words, keeping 2708 word types\n",
      "2022-04-02 11:42:16,827 : INFO : PROGRESS: at sentence #170000, processed 170000 words, keeping 2760 word types\n",
      "2022-04-02 11:42:16,850 : INFO : PROGRESS: at sentence #180000, processed 180000 words, keeping 2803 word types\n",
      "2022-04-02 11:42:16,943 : INFO : PROGRESS: at sentence #190000, processed 190000 words, keeping 2827 word types\n",
      "2022-04-02 11:42:16,998 : INFO : PROGRESS: at sentence #200000, processed 200000 words, keeping 2852 word types\n",
      "2022-04-02 11:42:17,021 : INFO : PROGRESS: at sentence #210000, processed 210000 words, keeping 2876 word types\n",
      "2022-04-02 11:42:17,085 : INFO : PROGRESS: at sentence #220000, processed 220000 words, keeping 2901 word types\n",
      "2022-04-02 11:42:17,106 : INFO : PROGRESS: at sentence #230000, processed 230000 words, keeping 2943 word types\n",
      "2022-04-02 11:42:17,171 : INFO : PROGRESS: at sentence #240000, processed 240000 words, keeping 2965 word types\n",
      "2022-04-02 11:42:17,188 : INFO : PROGRESS: at sentence #250000, processed 250000 words, keeping 2984 word types\n",
      "2022-04-02 11:42:17,243 : INFO : PROGRESS: at sentence #260000, processed 260000 words, keeping 3001 word types\n",
      "2022-04-02 11:42:17,262 : INFO : PROGRESS: at sentence #270000, processed 270000 words, keeping 3024 word types\n",
      "2022-04-02 11:42:17,316 : INFO : PROGRESS: at sentence #280000, processed 280000 words, keeping 3060 word types\n",
      "2022-04-02 11:42:17,338 : INFO : PROGRESS: at sentence #290000, processed 290000 words, keeping 3075 word types\n",
      "2022-04-02 11:42:17,375 : INFO : PROGRESS: at sentence #300000, processed 300000 words, keeping 3094 word types\n",
      "2022-04-02 11:42:17,396 : INFO : PROGRESS: at sentence #310000, processed 310000 words, keeping 3123 word types\n",
      "2022-04-02 11:42:17,433 : INFO : PROGRESS: at sentence #320000, processed 320000 words, keeping 3153 word types\n",
      "2022-04-02 11:42:17,454 : INFO : PROGRESS: at sentence #330000, processed 330000 words, keeping 3174 word types\n",
      "2022-04-02 11:42:17,486 : INFO : PROGRESS: at sentence #340000, processed 340000 words, keeping 3192 word types\n",
      "2022-04-02 11:42:17,499 : INFO : PROGRESS: at sentence #350000, processed 350000 words, keeping 3217 word types\n",
      "2022-04-02 11:42:17,544 : INFO : PROGRESS: at sentence #360000, processed 360000 words, keeping 3244 word types\n",
      "2022-04-02 11:42:17,562 : INFO : PROGRESS: at sentence #370000, processed 370000 words, keeping 3257 word types\n",
      "2022-04-02 11:42:17,611 : INFO : PROGRESS: at sentence #380000, processed 380000 words, keeping 3275 word types\n",
      "2022-04-02 11:42:17,629 : INFO : PROGRESS: at sentence #390000, processed 390000 words, keeping 3283 word types\n",
      "2022-04-02 11:42:17,664 : INFO : PROGRESS: at sentence #400000, processed 400000 words, keeping 3305 word types\n",
      "2022-04-02 11:42:17,679 : INFO : PROGRESS: at sentence #410000, processed 410000 words, keeping 3321 word types\n",
      "2022-04-02 11:42:17,726 : INFO : PROGRESS: at sentence #420000, processed 420000 words, keeping 3334 word types\n",
      "2022-04-02 11:42:17,746 : INFO : PROGRESS: at sentence #430000, processed 430000 words, keeping 3343 word types\n",
      "2022-04-02 11:42:17,773 : INFO : PROGRESS: at sentence #440000, processed 440000 words, keeping 3348 word types\n",
      "2022-04-02 11:42:17,796 : INFO : PROGRESS: at sentence #450000, processed 450000 words, keeping 3361 word types\n",
      "2022-04-02 11:42:17,826 : INFO : PROGRESS: at sentence #460000, processed 460000 words, keeping 3379 word types\n",
      "2022-04-02 11:42:17,849 : INFO : PROGRESS: at sentence #470000, processed 470000 words, keeping 3394 word types\n",
      "2022-04-02 11:42:17,881 : INFO : PROGRESS: at sentence #480000, processed 480000 words, keeping 3407 word types\n",
      "2022-04-02 11:42:17,904 : INFO : PROGRESS: at sentence #490000, processed 490000 words, keeping 3417 word types\n",
      "2022-04-02 11:42:17,927 : INFO : PROGRESS: at sentence #500000, processed 500000 words, keeping 3428 word types\n",
      "2022-04-02 11:42:17,947 : INFO : PROGRESS: at sentence #510000, processed 510000 words, keeping 3447 word types\n",
      "2022-04-02 11:42:17,966 : INFO : PROGRESS: at sentence #520000, processed 520000 words, keeping 3466 word types\n",
      "2022-04-02 11:42:17,992 : INFO : PROGRESS: at sentence #530000, processed 530000 words, keeping 3476 word types\n",
      "2022-04-02 11:42:18,026 : INFO : PROGRESS: at sentence #540000, processed 540000 words, keeping 3495 word types\n",
      "2022-04-02 11:42:18,049 : INFO : PROGRESS: at sentence #550000, processed 550000 words, keeping 3500 word types\n",
      "2022-04-02 11:42:18,105 : INFO : PROGRESS: at sentence #560000, processed 560000 words, keeping 3514 word types\n",
      "2022-04-02 11:42:18,125 : INFO : PROGRESS: at sentence #570000, processed 570000 words, keeping 3521 word types\n",
      "2022-04-02 11:42:18,150 : INFO : PROGRESS: at sentence #580000, processed 580000 words, keeping 3529 word types\n",
      "2022-04-02 11:42:18,175 : INFO : PROGRESS: at sentence #590000, processed 590000 words, keeping 3536 word types\n",
      "2022-04-02 11:42:18,190 : INFO : PROGRESS: at sentence #600000, processed 600000 words, keeping 3543 word types\n",
      "2022-04-02 11:42:18,204 : INFO : PROGRESS: at sentence #610000, processed 610000 words, keeping 3551 word types\n",
      "2022-04-02 11:42:18,237 : INFO : PROGRESS: at sentence #620000, processed 620000 words, keeping 3559 word types\n",
      "2022-04-02 11:42:18,258 : INFO : PROGRESS: at sentence #630000, processed 630000 words, keeping 3563 word types\n",
      "2022-04-02 11:42:18,297 : INFO : PROGRESS: at sentence #640000, processed 640000 words, keeping 3581 word types\n",
      "2022-04-02 11:42:18,358 : INFO : PROGRESS: at sentence #650000, processed 650000 words, keeping 3591 word types\n",
      "2022-04-02 11:42:18,375 : INFO : PROGRESS: at sentence #660000, processed 660000 words, keeping 3598 word types\n",
      "2022-04-02 11:42:18,393 : INFO : PROGRESS: at sentence #670000, processed 670000 words, keeping 3609 word types\n",
      "2022-04-02 11:42:18,444 : INFO : PROGRESS: at sentence #680000, processed 680000 words, keeping 3618 word types\n",
      "2022-04-02 11:42:18,463 : INFO : PROGRESS: at sentence #690000, processed 690000 words, keeping 3623 word types\n",
      "2022-04-02 11:42:18,511 : INFO : PROGRESS: at sentence #700000, processed 700000 words, keeping 3634 word types\n",
      "2022-04-02 11:42:18,539 : INFO : PROGRESS: at sentence #710000, processed 710000 words, keeping 3638 word types\n",
      "2022-04-02 11:42:18,599 : INFO : PROGRESS: at sentence #720000, processed 720000 words, keeping 3654 word types\n",
      "2022-04-02 11:42:18,617 : INFO : PROGRESS: at sentence #730000, processed 730000 words, keeping 3656 word types\n",
      "2022-04-02 11:42:18,682 : INFO : PROGRESS: at sentence #740000, processed 740000 words, keeping 3662 word types\n",
      "2022-04-02 11:42:18,695 : INFO : PROGRESS: at sentence #750000, processed 750000 words, keeping 3670 word types\n",
      "2022-04-02 11:42:18,708 : INFO : PROGRESS: at sentence #760000, processed 760000 words, keeping 3680 word types\n",
      "2022-04-02 11:42:18,781 : INFO : PROGRESS: at sentence #770000, processed 770000 words, keeping 3684 word types\n",
      "2022-04-02 11:42:18,800 : INFO : PROGRESS: at sentence #780000, processed 780000 words, keeping 3697 word types\n",
      "2022-04-02 11:42:18,892 : INFO : PROGRESS: at sentence #790000, processed 790000 words, keeping 3703 word types\n",
      "2022-04-02 11:42:18,908 : INFO : PROGRESS: at sentence #800000, processed 800000 words, keeping 3710 word types\n",
      "2022-04-02 11:42:18,924 : INFO : PROGRESS: at sentence #810000, processed 810000 words, keeping 3730 word types\n",
      "2022-04-02 11:42:18,988 : INFO : PROGRESS: at sentence #820000, processed 820000 words, keeping 3741 word types\n",
      "2022-04-02 11:42:18,998 : INFO : PROGRESS: at sentence #830000, processed 830000 words, keeping 3748 word types\n",
      "2022-04-02 11:42:19,055 : INFO : PROGRESS: at sentence #840000, processed 840000 words, keeping 3753 word types\n",
      "2022-04-02 11:42:19,078 : INFO : PROGRESS: at sentence #850000, processed 850000 words, keeping 3758 word types\n",
      "2022-04-02 11:42:19,092 : INFO : PROGRESS: at sentence #860000, processed 860000 words, keeping 3764 word types\n",
      "2022-04-02 11:42:19,155 : INFO : PROGRESS: at sentence #870000, processed 870000 words, keeping 3773 word types\n",
      "2022-04-02 11:42:19,171 : INFO : PROGRESS: at sentence #880000, processed 880000 words, keeping 3780 word types\n",
      "2022-04-02 11:42:19,191 : INFO : PROGRESS: at sentence #890000, processed 890000 words, keeping 3793 word types\n",
      "2022-04-02 11:42:19,210 : INFO : PROGRESS: at sentence #900000, processed 900000 words, keeping 3802 word types\n",
      "2022-04-02 11:42:19,249 : INFO : PROGRESS: at sentence #910000, processed 910000 words, keeping 3817 word types\n",
      "2022-04-02 11:42:19,270 : INFO : PROGRESS: at sentence #920000, processed 920000 words, keeping 3832 word types\n",
      "2022-04-02 11:42:19,325 : INFO : PROGRESS: at sentence #930000, processed 930000 words, keeping 3846 word types\n",
      "2022-04-02 11:42:19,349 : INFO : PROGRESS: at sentence #940000, processed 940000 words, keeping 3858 word types\n",
      "2022-04-02 11:42:19,424 : INFO : PROGRESS: at sentence #950000, processed 950000 words, keeping 3879 word types\n",
      "2022-04-02 11:42:19,444 : INFO : PROGRESS: at sentence #960000, processed 960000 words, keeping 3888 word types\n",
      "2022-04-02 11:42:19,481 : INFO : PROGRESS: at sentence #970000, processed 970000 words, keeping 3890 word types\n",
      "2022-04-02 11:42:19,523 : INFO : PROGRESS: at sentence #980000, processed 980000 words, keeping 3906 word types\n",
      "2022-04-02 11:42:19,545 : INFO : PROGRESS: at sentence #990000, processed 990000 words, keeping 3916 word types\n",
      "2022-04-02 11:42:19,604 : INFO : PROGRESS: at sentence #1000000, processed 1000000 words, keeping 3922 word types\n",
      "2022-04-02 11:42:19,622 : INFO : PROGRESS: at sentence #1010000, processed 1010000 words, keeping 3931 word types\n",
      "2022-04-02 11:42:19,654 : INFO : PROGRESS: at sentence #1020000, processed 1020000 words, keeping 3946 word types\n",
      "2022-04-02 11:42:19,670 : INFO : PROGRESS: at sentence #1030000, processed 1030000 words, keeping 3954 word types\n",
      "2022-04-02 11:42:19,707 : INFO : PROGRESS: at sentence #1040000, processed 1040000 words, keeping 3964 word types\n",
      "2022-04-02 11:42:19,721 : INFO : PROGRESS: at sentence #1050000, processed 1050000 words, keeping 3977 word types\n",
      "2022-04-02 11:42:19,757 : INFO : PROGRESS: at sentence #1060000, processed 1060000 words, keeping 3984 word types\n",
      "2022-04-02 11:42:19,777 : INFO : PROGRESS: at sentence #1070000, processed 1070000 words, keeping 3987 word types\n",
      "2022-04-02 11:42:19,811 : INFO : PROGRESS: at sentence #1080000, processed 1080000 words, keeping 3989 word types\n",
      "2022-04-02 11:42:19,832 : INFO : PROGRESS: at sentence #1090000, processed 1090000 words, keeping 3993 word types\n",
      "2022-04-02 11:42:19,858 : INFO : PROGRESS: at sentence #1100000, processed 1100000 words, keeping 3999 word types\n",
      "2022-04-02 11:42:19,878 : INFO : PROGRESS: at sentence #1110000, processed 1110000 words, keeping 4009 word types\n",
      "2022-04-02 11:42:19,899 : INFO : PROGRESS: at sentence #1120000, processed 1120000 words, keeping 4014 word types\n",
      "2022-04-02 11:42:19,919 : INFO : PROGRESS: at sentence #1130000, processed 1130000 words, keeping 4020 word types\n",
      "2022-04-02 11:42:19,942 : INFO : PROGRESS: at sentence #1140000, processed 1140000 words, keeping 4028 word types\n",
      "2022-04-02 11:42:19,963 : INFO : PROGRESS: at sentence #1150000, processed 1150000 words, keeping 4034 word types\n",
      "2022-04-02 11:42:19,982 : INFO : PROGRESS: at sentence #1160000, processed 1160000 words, keeping 4044 word types\n",
      "2022-04-02 11:42:20,002 : INFO : PROGRESS: at sentence #1170000, processed 1170000 words, keeping 4049 word types\n",
      "2022-04-02 11:42:20,017 : INFO : PROGRESS: at sentence #1180000, processed 1180000 words, keeping 4052 word types\n",
      "2022-04-02 11:42:20,031 : INFO : PROGRESS: at sentence #1190000, processed 1190000 words, keeping 4059 word types\n",
      "2022-04-02 11:42:20,049 : INFO : PROGRESS: at sentence #1200000, processed 1200000 words, keeping 4064 word types\n",
      "2022-04-02 11:42:20,076 : INFO : PROGRESS: at sentence #1210000, processed 1210000 words, keeping 4072 word types\n",
      "2022-04-02 11:42:20,094 : INFO : PROGRESS: at sentence #1220000, processed 1220000 words, keeping 4073 word types\n",
      "2022-04-02 11:42:20,112 : INFO : PROGRESS: at sentence #1230000, processed 1230000 words, keeping 4077 word types\n",
      "2022-04-02 11:42:20,132 : INFO : PROGRESS: at sentence #1240000, processed 1240000 words, keeping 4081 word types\n",
      "2022-04-02 11:42:20,157 : INFO : PROGRESS: at sentence #1250000, processed 1250000 words, keeping 4083 word types\n",
      "2022-04-02 11:42:20,173 : INFO : PROGRESS: at sentence #1260000, processed 1260000 words, keeping 4088 word types\n",
      "2022-04-02 11:42:20,188 : INFO : PROGRESS: at sentence #1270000, processed 1270000 words, keeping 4095 word types\n",
      "2022-04-02 11:42:20,208 : INFO : PROGRESS: at sentence #1280000, processed 1280000 words, keeping 4108 word types\n",
      "2022-04-02 11:42:20,228 : INFO : PROGRESS: at sentence #1290000, processed 1290000 words, keeping 4113 word types\n",
      "2022-04-02 11:42:20,266 : INFO : PROGRESS: at sentence #1300000, processed 1300000 words, keeping 4120 word types\n",
      "2022-04-02 11:42:20,282 : INFO : PROGRESS: at sentence #1310000, processed 1310000 words, keeping 4125 word types\n",
      "2022-04-02 11:42:20,309 : INFO : PROGRESS: at sentence #1320000, processed 1320000 words, keeping 4130 word types\n",
      "2022-04-02 11:42:20,341 : INFO : PROGRESS: at sentence #1330000, processed 1330000 words, keeping 4137 word types\n",
      "2022-04-02 11:42:20,389 : INFO : PROGRESS: at sentence #1340000, processed 1340000 words, keeping 4142 word types\n",
      "2022-04-02 11:42:20,405 : INFO : PROGRESS: at sentence #1350000, processed 1350000 words, keeping 4150 word types\n",
      "2022-04-02 11:42:20,444 : INFO : PROGRESS: at sentence #1360000, processed 1360000 words, keeping 4153 word types\n",
      "2022-04-02 11:42:20,460 : INFO : PROGRESS: at sentence #1370000, processed 1370000 words, keeping 4161 word types\n",
      "2022-04-02 11:42:20,498 : INFO : PROGRESS: at sentence #1380000, processed 1380000 words, keeping 4167 word types\n",
      "2022-04-02 11:42:20,522 : INFO : PROGRESS: at sentence #1390000, processed 1390000 words, keeping 4170 word types\n",
      "2022-04-02 11:42:20,547 : INFO : PROGRESS: at sentence #1400000, processed 1400000 words, keeping 4174 word types\n",
      "2022-04-02 11:42:20,563 : INFO : PROGRESS: at sentence #1410000, processed 1410000 words, keeping 4178 word types\n",
      "2022-04-02 11:42:20,591 : INFO : PROGRESS: at sentence #1420000, processed 1420000 words, keeping 4182 word types\n",
      "2022-04-02 11:42:20,607 : INFO : PROGRESS: at sentence #1430000, processed 1430000 words, keeping 4192 word types\n",
      "2022-04-02 11:42:20,633 : INFO : PROGRESS: at sentence #1440000, processed 1440000 words, keeping 4198 word types\n",
      "2022-04-02 11:42:20,655 : INFO : PROGRESS: at sentence #1450000, processed 1450000 words, keeping 4200 word types\n",
      "2022-04-02 11:42:20,692 : INFO : PROGRESS: at sentence #1460000, processed 1460000 words, keeping 4208 word types\n",
      "2022-04-02 11:42:20,709 : INFO : PROGRESS: at sentence #1470000, processed 1470000 words, keeping 4213 word types\n",
      "2022-04-02 11:42:20,740 : INFO : PROGRESS: at sentence #1480000, processed 1480000 words, keeping 4221 word types\n",
      "2022-04-02 11:42:20,759 : INFO : PROGRESS: at sentence #1490000, processed 1490000 words, keeping 4224 word types\n",
      "2022-04-02 11:42:20,778 : INFO : PROGRESS: at sentence #1500000, processed 1500000 words, keeping 4228 word types\n",
      "2022-04-02 11:42:20,794 : INFO : PROGRESS: at sentence #1510000, processed 1510000 words, keeping 4229 word types\n",
      "2022-04-02 11:42:20,816 : INFO : PROGRESS: at sentence #1520000, processed 1520000 words, keeping 4231 word types\n",
      "2022-04-02 11:42:20,830 : INFO : PROGRESS: at sentence #1530000, processed 1530000 words, keeping 4233 word types\n",
      "2022-04-02 11:42:20,847 : INFO : PROGRESS: at sentence #1540000, processed 1540000 words, keeping 4238 word types\n",
      "2022-04-02 11:42:20,870 : INFO : PROGRESS: at sentence #1550000, processed 1550000 words, keeping 4246 word types\n",
      "2022-04-02 11:42:20,899 : INFO : PROGRESS: at sentence #1560000, processed 1560000 words, keeping 4248 word types\n",
      "2022-04-02 11:42:20,928 : INFO : PROGRESS: at sentence #1570000, processed 1570000 words, keeping 4249 word types\n",
      "2022-04-02 11:42:20,971 : INFO : PROGRESS: at sentence #1580000, processed 1580000 words, keeping 4249 word types\n",
      "2022-04-02 11:42:20,989 : INFO : PROGRESS: at sentence #1590000, processed 1590000 words, keeping 4252 word types\n",
      "2022-04-02 11:42:21,031 : INFO : PROGRESS: at sentence #1600000, processed 1600000 words, keeping 4257 word types\n",
      "2022-04-02 11:42:21,053 : INFO : PROGRESS: at sentence #1610000, processed 1610000 words, keeping 4258 word types\n",
      "2022-04-02 11:42:21,080 : INFO : PROGRESS: at sentence #1620000, processed 1620000 words, keeping 4268 word types\n",
      "2022-04-02 11:42:21,099 : INFO : PROGRESS: at sentence #1630000, processed 1630000 words, keeping 4270 word types\n",
      "2022-04-02 11:42:21,112 : INFO : PROGRESS: at sentence #1640000, processed 1640000 words, keeping 4279 word types\n",
      "2022-04-02 11:42:21,163 : INFO : PROGRESS: at sentence #1650000, processed 1650000 words, keeping 4282 word types\n",
      "2022-04-02 11:42:21,187 : INFO : PROGRESS: at sentence #1660000, processed 1660000 words, keeping 4289 word types\n",
      "2022-04-02 11:42:21,202 : INFO : PROGRESS: at sentence #1670000, processed 1670000 words, keeping 4293 word types\n",
      "2022-04-02 11:42:21,233 : INFO : PROGRESS: at sentence #1680000, processed 1680000 words, keeping 4298 word types\n",
      "2022-04-02 11:42:21,252 : INFO : PROGRESS: at sentence #1690000, processed 1690000 words, keeping 4301 word types\n",
      "2022-04-02 11:42:21,276 : INFO : PROGRESS: at sentence #1700000, processed 1700000 words, keeping 4308 word types\n",
      "2022-04-02 11:42:21,306 : INFO : PROGRESS: at sentence #1710000, processed 1710000 words, keeping 4315 word types\n",
      "2022-04-02 11:42:21,326 : INFO : PROGRESS: at sentence #1720000, processed 1720000 words, keeping 4318 word types\n",
      "2022-04-02 11:42:21,367 : INFO : PROGRESS: at sentence #1730000, processed 1730000 words, keeping 4322 word types\n",
      "2022-04-02 11:42:21,393 : INFO : PROGRESS: at sentence #1740000, processed 1740000 words, keeping 4328 word types\n",
      "2022-04-02 11:42:21,444 : INFO : PROGRESS: at sentence #1750000, processed 1750000 words, keeping 4334 word types\n",
      "2022-04-02 11:42:21,491 : INFO : PROGRESS: at sentence #1760000, processed 1760000 words, keeping 4340 word types\n",
      "2022-04-02 11:42:21,510 : INFO : PROGRESS: at sentence #1770000, processed 1770000 words, keeping 4343 word types\n",
      "2022-04-02 11:42:21,564 : INFO : PROGRESS: at sentence #1780000, processed 1780000 words, keeping 4349 word types\n",
      "2022-04-02 11:42:21,582 : INFO : PROGRESS: at sentence #1790000, processed 1790000 words, keeping 4349 word types\n",
      "2022-04-02 11:42:21,612 : INFO : PROGRESS: at sentence #1800000, processed 1800000 words, keeping 4353 word types\n",
      "2022-04-02 11:42:21,638 : INFO : PROGRESS: at sentence #1810000, processed 1810000 words, keeping 4355 word types\n",
      "2022-04-02 11:42:21,665 : INFO : PROGRESS: at sentence #1820000, processed 1820000 words, keeping 4366 word types\n",
      "2022-04-02 11:42:21,687 : INFO : PROGRESS: at sentence #1830000, processed 1830000 words, keeping 4368 word types\n",
      "2022-04-02 11:42:21,711 : INFO : PROGRESS: at sentence #1840000, processed 1840000 words, keeping 4370 word types\n",
      "2022-04-02 11:42:21,735 : INFO : PROGRESS: at sentence #1850000, processed 1850000 words, keeping 4378 word types\n",
      "2022-04-02 11:42:21,778 : INFO : collected 4380 word types from a corpus of 1859997 raw words and 1859997 sentences\n",
      "2022-04-02 11:42:21,781 : INFO : Creating a fresh vocabulary\n",
      "2022-04-02 11:42:21,928 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=1 retains 4380 unique words (100.0%% of original 4380, drops 0)', 'datetime': '2022-04-02T11:42:21.928595', 'gensim': '4.1.2', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2022-04-02 11:42:21,929 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 1859997 word corpus (100.0%% of original 1859997, drops 0)', 'datetime': '2022-04-02T11:42:21.929591', 'gensim': '4.1.2', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2022-04-02 11:42:22,119 : INFO : deleting the raw counts dictionary of 4380 items\n",
      "2022-04-02 11:42:22,120 : INFO : sample=0.001 downsamples 37 most-common words\n",
      "2022-04-02 11:42:22,121 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1220932.2855121107 word corpus (65.6%% of prior 1859997)', 'datetime': '2022-04-02T11:42:22.121078', 'gensim': '4.1.2', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2022-04-02 11:42:22,380 : INFO : estimated required memory for 4380 words and 100 dimensions: 5694000 bytes\n",
      "2022-04-02 11:42:22,381 : INFO : resetting layer weights\n",
      "2022-04-02 11:42:22,394 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-04-02T11:42:22.394348', 'gensim': '4.1.2', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'build_vocab'}\n",
      "2022-04-02 11:42:22,395 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4380 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-04-02T11:42:22.395344', 'gensim': '4.1.2', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "2022-04-02 11:42:23,841 : INFO : EPOCH 1 - PROGRESS: at 8.60% examples, 100410 words/s, in_qsize 0, out_qsize 2\n",
      "2022-04-02 11:42:24,860 : INFO : EPOCH 1 - PROGRESS: at 19.35% examples, 115010 words/s, in_qsize 5, out_qsize 1\n",
      "2022-04-02 11:42:25,867 : INFO : EPOCH 1 - PROGRESS: at 34.41% examples, 137957 words/s, in_qsize 0, out_qsize 0\n",
      "2022-04-02 11:42:26,873 : INFO : EPOCH 1 - PROGRESS: at 45.70% examples, 138104 words/s, in_qsize 6, out_qsize 0\n",
      "2022-04-02 11:42:27,928 : INFO : EPOCH 1 - PROGRESS: at 56.45% examples, 134969 words/s, in_qsize 2, out_qsize 0\n",
      "2022-04-02 11:42:28,981 : INFO : EPOCH 1 - PROGRESS: at 66.67% examples, 132440 words/s, in_qsize 0, out_qsize 0\n",
      "2022-04-02 11:42:30,059 : INFO : EPOCH 1 - PROGRESS: at 77.96% examples, 131534 words/s, in_qsize 2, out_qsize 0\n",
      "2022-04-02 11:42:31,114 : INFO : EPOCH 1 - PROGRESS: at 90.32% examples, 132826 words/s, in_qsize 4, out_qsize 1\n",
      "2022-04-02 11:42:31,634 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-02 11:42:31,648 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-02 11:42:31,663 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-02 11:42:31,664 : INFO : EPOCH - 1 : training on 1859997 raw words (1221419 effective words) took 8.9s, 137512 effective words/s\n",
      "2022-04-02 11:42:32,933 : INFO : EPOCH 2 - PROGRESS: at 12.37% examples, 146586 words/s, in_qsize 5, out_qsize 1\n",
      "2022-04-02 11:42:33,972 : INFO : EPOCH 2 - PROGRESS: at 22.58% examples, 134073 words/s, in_qsize 5, out_qsize 0\n",
      "2022-04-02 11:42:35,000 : INFO : EPOCH 2 - PROGRESS: at 36.56% examples, 145427 words/s, in_qsize 5, out_qsize 0\n",
      "2022-04-02 11:42:36,034 : INFO : EPOCH 2 - PROGRESS: at 54.30% examples, 161452 words/s, in_qsize 6, out_qsize 0\n",
      "2022-04-02 11:42:37,045 : INFO : EPOCH 2 - PROGRESS: at 72.04% examples, 171966 words/s, in_qsize 4, out_qsize 1\n",
      "2022-04-02 11:42:38,048 : INFO : EPOCH 2 - PROGRESS: at 88.17% examples, 175607 words/s, in_qsize 5, out_qsize 2\n",
      "2022-04-02 11:42:38,429 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-02 11:42:38,430 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-02 11:42:38,440 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-02 11:42:38,441 : INFO : EPOCH - 2 : training on 1859997 raw words (1221022 effective words) took 6.5s, 186478 effective words/s\n",
      "2022-04-02 11:42:39,478 : INFO : EPOCH 3 - PROGRESS: at 13.44% examples, 164235 words/s, in_qsize 4, out_qsize 1\n",
      "2022-04-02 11:42:40,489 : INFO : EPOCH 3 - PROGRESS: at 33.87% examples, 207141 words/s, in_qsize 5, out_qsize 1\n",
      "2022-04-02 11:42:41,526 : INFO : EPOCH 3 - PROGRESS: at 52.69% examples, 212194 words/s, in_qsize 6, out_qsize 0\n",
      "2022-04-02 11:42:42,547 : INFO : EPOCH 3 - PROGRESS: at 72.58% examples, 218729 words/s, in_qsize 4, out_qsize 1\n",
      "2022-04-02 11:42:43,614 : INFO : EPOCH 3 - PROGRESS: at 95.16% examples, 225800 words/s, in_qsize 6, out_qsize 0\n",
      "2022-04-02 11:42:43,776 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-02 11:42:43,778 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-02 11:42:43,793 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-02 11:42:43,795 : INFO : EPOCH - 3 : training on 1859997 raw words (1220639 effective words) took 5.3s, 229106 effective words/s\n",
      "2022-04-02 11:42:44,911 : INFO : EPOCH 4 - PROGRESS: at 8.60% examples, 101032 words/s, in_qsize 5, out_qsize 1\n",
      "2022-04-02 11:42:45,959 : INFO : EPOCH 4 - PROGRESS: at 22.58% examples, 132910 words/s, in_qsize 5, out_qsize 0\n",
      "2022-04-02 11:42:46,979 : INFO : EPOCH 4 - PROGRESS: at 38.17% examples, 151322 words/s, in_qsize 5, out_qsize 0\n",
      "2022-04-02 11:42:48,013 : INFO : EPOCH 4 - PROGRESS: at 60.75% examples, 179788 words/s, in_qsize 4, out_qsize 1\n",
      "2022-04-02 11:42:49,030 : INFO : EPOCH 4 - PROGRESS: at 82.80% examples, 196522 words/s, in_qsize 5, out_qsize 0\n",
      "2022-04-02 11:42:49,680 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-02 11:42:49,682 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-02 11:42:49,695 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-02 11:42:49,696 : INFO : EPOCH - 4 : training on 1859997 raw words (1220972 effective words) took 5.8s, 209224 effective words/s\n",
      "2022-04-02 11:42:50,731 : INFO : EPOCH 5 - PROGRESS: at 14.52% examples, 178028 words/s, in_qsize 6, out_qsize 0\n",
      "2022-04-02 11:42:51,743 : INFO : EPOCH 5 - PROGRESS: at 34.41% examples, 210644 words/s, in_qsize 6, out_qsize 0\n",
      "2022-04-02 11:42:52,766 : INFO : EPOCH 5 - PROGRESS: at 54.84% examples, 221786 words/s, in_qsize 5, out_qsize 0\n",
      "2022-04-02 11:42:53,830 : INFO : EPOCH 5 - PROGRESS: at 75.81% examples, 226694 words/s, in_qsize 4, out_qsize 1\n",
      "2022-04-02 11:42:54,881 : INFO : EPOCH 5 - PROGRESS: at 90.86% examples, 215601 words/s, in_qsize 6, out_qsize 0\n",
      "2022-04-02 11:42:55,332 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-02 11:42:55,334 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-02 11:42:55,350 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-02 11:42:55,354 : INFO : EPOCH - 5 : training on 1859997 raw words (1220705 effective words) took 5.6s, 216819 effective words/s\n",
      "2022-04-02 11:42:55,355 : INFO : Word2Vec lifecycle event {'msg': 'training on 9299985 raw words (6104757 effective words) took 33.0s, 185224 effective words/s', 'datetime': '2022-04-02T11:42:55.355597', 'gensim': '4.1.2', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "2022-04-02 11:42:55,358 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=4380, vector_size=100, alpha=0.025)', 'datetime': '2022-04-02T11:42:55.358588', 'gensim': '4.1.2', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'created'}\n",
      "2022-04-02 11:42:55,359 : INFO : Word2Vec lifecycle event {'fname_or_handle': './models/Word2vec_v1.pkl', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2022-04-02T11:42:55.359586', 'gensim': '4.1.2', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'saving'}\n",
      "2022-04-02 11:42:55,361 : INFO : not storing attribute cum_table\n",
      "2022-04-02 11:42:55,378 : INFO : saved ./models/Word2vec_v1.pkl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO) \n",
    "\n",
    "model = Word2Vec(content,     # 上文处理过的全部语料\n",
    "                 min_count=1,  # 词频阈值 词出现的频率 小于这个频率的词 将不予保存\n",
    "                 window=5  # 窗口大小 表示当前词与预测词在一个句子中的最大距离是多少\n",
    "                 )\n",
    "model.save('./models/Word2vec_v1.pkl')  # 保存模型\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-02 11:43:04,939 : INFO : loading Word2Vec object from ./models/Word2vec_v1.pkl\n",
      "2022-04-02 11:43:04,962 : INFO : loading wv recursively from ./models/Word2vec_v1.pkl.wv.* with mmap=None\n",
      "2022-04-02 11:43:04,963 : INFO : setting ignored attribute cum_table to None\n",
      "2022-04-02 11:43:05,118 : INFO : Word2Vec lifecycle event {'fname': './models/Word2vec_v1.pkl', 'datetime': '2022-04-02T11:43:05.118155', 'gensim': '4.1.2', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'loaded'}\n"
     ]
    }
   ],
   "source": [
    "#创建词语字典，并返回word2vec模型中词语的索引，词向量\n",
    "\n",
    "def create_dictionaries(model):\n",
    "\n",
    "    gensim_dict = Dictionary()    # 创建词语词典\n",
    "    gensim_dict.doc2bow(model.wv.key_to_index.keys(), allow_update=True)\n",
    "\n",
    "    w2indx = {v: k + 1 for k, v in gensim_dict.items()}  # 词语的索引，从1开始编号\n",
    "    w2vec = {word: model.wv[word] for word in w2indx.keys()}  # 词语的词向量\n",
    "    return w2indx, w2vec\n",
    "\n",
    "model = Word2Vec.load('./models/Word2vec_v1.pkl')         # 加载模型\n",
    "index_dict, word_vectors= create_dictionaries(model)  # 索引字典、词向量字典\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参数设置\n",
    "vocab_dim = 150 # 向量维度\n",
    "maxlen = 150 # 文本保留的最大长度\n",
    "batch_size = 100 # 训练过程中 每次传入模型的特征数量\n",
    "n_epoch = 1   # 迭代次数\n",
    "\n",
    "n_symbols = len(index_dict) + 1  # 索引数字的个数，因为有的词语索引为0，所以+1\n",
    "embedding_weights = np.zeros((n_symbols, 100))  # 创建一个n_symbols * 100的0矩阵\n",
    "\n",
    "for w, index in index_dict.items():  # 从索引为1的词语开始，用词向量填充矩阵\n",
    "    embedding_weights[index, :] = word_vectors[w]  # 词向量矩阵，第一行是0向量（没有索引为0的词语，未被填充）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_index_array(p_new_dic, p_sen): \n",
    "    \"\"\"\n",
    "    文本或列表转换为索引数字\n",
    "    :param p_new_dic:\n",
    "    :param p_sen:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if type(p_sen) == list:\n",
    "        new_sentences = []\n",
    "        for sen in p_sen:\n",
    "            new_sen = []\n",
    "            for word in sen:\n",
    "                try:\n",
    "                    new_sen.append(p_new_dic[word])  # 单词转索引数字\n",
    "                except:\n",
    "                    new_sen.append(0)  # 索引字典里没有的词转为数字0\n",
    "            new_sentences.append(new_sen)\n",
    "        return np.array(new_sentences)   # 转numpy数组\n",
    "    else:\n",
    "        new_sentences = []\n",
    "        sentences = []\n",
    "        p_sen = p_sen.split(\" \")\n",
    "        for word in p_sen:\n",
    "            try:\n",
    "                sentences.append(p_new_dic[word])  # 单词转索引数字\n",
    "            except:\n",
    "                sentences.append(0)  # 索引字典里没有的词转为数字0\n",
    "        new_sentences.append(sentences)\n",
    "        return new_sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\u1128714\\.conda\\envs\\nlp_base\\lib\\site-packages\\ipykernel_launcher.py:18: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集shape：  (82447,)\n",
      "测试集shape：  (20612,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "'''\n",
    "with open(\"./原始语料/neg.txt\", \"r\", encoding='UTF-8') as f:\n",
    "            neg_data1 = f.readlines()\n",
    "\n",
    "with open(\"./原始语料/pos.txt\", \"r\", encoding='UTF-8') as g:\n",
    "    pos_data1 = g.readlines()\n",
    "\n",
    "neg_data = sorted(set(neg_data1), key=neg_data1.index)  #列表去重 保持原来的顺序\n",
    "pos_data = sorted(set(pos_data1), key=pos_data1.index)\n",
    "\n",
    "neg_data = [process_txt(data) for data in neg_data]\n",
    "pos_data = [process_txt(data) for data in pos_data]\n",
    "data = neg_data + pos_data\n",
    "\n",
    "\n",
    "# 读取语料类别标签\n",
    "label_list = ([0] * len(neg_data) + [1] * len(pos_data))\n",
    "'''\n",
    "\n",
    "labels, vocabulary = list(data['class']), list(data['评论文本'])\n",
    "\n",
    "# 划分训练集和测试集，此时都是list列表\n",
    "X_train_l, X_test_l, y_train_l, y_test_l = train_test_split(vocabulary, labels, test_size=0.2)\n",
    "\n",
    "# 转为数字索引形式\n",
    "\n",
    "# token = Tokenizer(num_words=3000)   #字典数量\n",
    "# token.fit_on_texts(train_text)\n",
    "\n",
    "X_train = text_to_index_array(index_dict, X_train_l)\n",
    "X_test = text_to_index_array(index_dict, X_test_l)\n",
    "\n",
    "y_train = np.array(y_train_l)  # 转numpy数组\n",
    "y_test = np.array(y_test_l)\n",
    "\n",
    "print(\"训练集shape： \", X_train.shape)\n",
    "print(\"测试集shape： \", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参数设置\n",
    "vocab_dim = 150 # 向量维度\n",
    "maxlen = 150 # 文本保留的最大长度\n",
    "batch_size = 100 # 训练过程中 每次传入模型的特征数量\n",
    "n_epoch = 1   # 迭代次数\n",
    "\n",
    "X_train = pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, maxlen=maxlen)\n",
    "\n",
    "n_symbols = len(index_dict) + 1  # 索引数字的个数，因为有的词语索引为0，所以+1\n",
    "embedding_weights = np.zeros((n_symbols, 100))  # 创建一个n_symbols * 100的0矩阵\n",
    "\n",
    "for w, index in index_dict.items():  # 从索引为1的词语开始，用词向量填充矩阵\n",
    "    embedding_weights[index, :] = word_vectors[w]  # 词向量矩阵，第一行是0向量（没有索引为0的词语，未被填充）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_train_history(train_history,train, velidation):\n",
    "    \"\"\"\n",
    "    可视化训练过程 对比\n",
    "    :param train_history:\n",
    "    :param train:\n",
    "    :param velidation:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    plt.plot(train_history.history[train])\n",
    "    plt.plot(train_history.history[velidation])\n",
    "    plt.title(\"Train History\")   #标题\n",
    "    plt.xlabel('Epoch')    #x轴标题\n",
    "    plt.ylabel(train)  #y轴标题\n",
    "    plt.legend(['train', 'test'], loc='upper left')  #图例 左上角\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lstm(p_n_symbols, p_embedding_weights, p_X_train, p_y_train, p_X_test, p_y_test, X_test_l):\n",
    "    print('...CREATING MODEL...')\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(output_dim=100,  # 输出向量维度\n",
    "                        input_dim=p_n_symbols,  # 词汇表的维度(总共有多少个不相同的词), 输入向量维度\n",
    "                        mask_zero=True,         # 使我们填补的0值在后续训练中不产生影响（屏蔽0值）\n",
    "                        weights=[p_embedding_weights],   # 对数据加权\n",
    "                        input_length=maxlen))      # 每个特征的长度\n",
    "\n",
    "    model.add(Bidirectional(LSTM(32, return_sequences = True)))\n",
    "    # using BiLSTM to represent every word and get the contextual information\n",
    "    model.add(GlobalAveragePooling1D())\n",
    "    # get the biggest numbers to represent a sentence\n",
    "    model.add(Dense(20, activation=\"relu\"))\n",
    "    # fully connected layer\n",
    "    model.add(Dropout(0.05))\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    model.summary()\n",
    "\n",
    "    print('...COMPILING...')\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    print(\"FINISH!!\")\n",
    "\n",
    "    print(\"...TRAINING...\")\n",
    "    train_history = model.fit(p_X_train, p_y_train, batch_size=batch_size, epochs=n_epoch,\n",
    "              validation_data=(p_X_test, p_y_test))\n",
    "\n",
    "    print(\"...EVALUATING...\")\n",
    "    score, acc = model.evaluate(p_X_test, p_y_test, batch_size=batch_size)\n",
    "    label = model.predict(p_X_test)\n",
    "    print('Test score:', score)\n",
    "    print('Test accuracy:', 1 - acc)\n",
    "    '''\n",
    "    for (a, b, c) in zip(p_y_test, X_test_l, labels):\n",
    "        print(\"原文为：\"+ \"\".join(b))\n",
    "        print(\"预测倾向为\", a)\n",
    "        print(\"真实倾向为\", c)\n",
    "\n",
    "    show_train_history(train_history, 'acc', 'val_acc')    # 训练集准确率与验证集准确率 折线图\n",
    "    show_train_history(train_history, 'loss', 'val_loss')  # 训练集误差率与验证集误差率 折线图\n",
    "    '''\n",
    "    \"\"\"SAVE MODEL\"\"\"\n",
    "    model.save('./models/emotion_model_LSTM.h5')\n",
    "    print(\"模型保存成功\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-02 11:47:47,257 : WARNING : From C:\\Users\\u1128714\\.conda\\envs\\nlp_base\\lib\\site-packages\\tensorflow\\python\\keras\\initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...CREATING MODEL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-02 11:47:47,687 : WARNING : From C:\\Users\\u1128714\\.conda\\envs\\nlp_base\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "2022-04-02 11:47:47,694 : WARNING : From C:\\Users\\u1128714\\.conda\\envs\\nlp_base\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "2022-04-02 11:47:47,705 : WARNING : From C:\\Users\\u1128714\\.conda\\envs\\nlp_base\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "2022-04-02 11:47:47,707 : WARNING : From C:\\Users\\u1128714\\.conda\\envs\\nlp_base\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "2022-04-02 11:47:48,855 : WARNING : From C:\\Users\\u1128714\\.conda\\envs\\nlp_base\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:3794: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 150, 100)          438100    \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 150, 64)           34048     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 20)                1300      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 473,469\n",
      "Trainable params: 473,469\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "...COMPILING...\n",
      "...TRAINING...\n",
      "Train on 82447 samples, validate on 20612 samples\n",
      "82447/82447 [==============================] - 577s 7ms/sample - loss: nan - acc: 2.4258e-05 - val_loss: nan - val_acc: 0.0000e+00\n",
      "...EVALUATING...\n",
      "20612/20612 [==============================] - 36s 2ms/sample - loss: nan - acc: 0.0000e+00\n",
      "Test score: nan\n",
      "Test accuracy: 0.0\n",
      "模型保存成功\n"
     ]
    }
   ],
   "source": [
    "train_lstm(p_n_symbols=embedding_weights.shape[0], p_embedding_weights=embedding_weights, p_X_train=X_train, p_y_train=y_train, p_X_test=X_test, p_y_test=y_test, X_test_l=X_test_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "25e46e56c89bac3086203569ebd849e4b8487df90197a735642ce1933f03773d"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('nlp_base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
